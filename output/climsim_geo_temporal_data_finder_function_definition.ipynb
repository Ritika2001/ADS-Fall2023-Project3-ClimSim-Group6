{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from huggingface_hub import hf_hub_download\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(url, mode):\n",
    "    if mode == 'train':\n",
    "        data_folder = \"../data/e3sm_train/\"\n",
    "    else:\n",
    "        data_folder = \"../data/e3sm_valid/\"\n",
    "\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    \n",
    "    if os.path.exists(data_folder + os.path.basename(url)):\n",
    "        print(f\"File already exists in {data_folder}. Skipping download.\")\n",
    "\n",
    "    else:\n",
    "        file_name = os.path.join(data_folder, url.split(\"/\")[-1])\n",
    "            \n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # file_name = url.split(\"/\")[-1]\n",
    "            with open(file_name, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"File downloaded and saved to {file_name}\")\n",
    "        else:\n",
    "            print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(training_period, validation_period):\n",
    "    data_base_url = \"https://huggingface.co/datasets/LEAP/ClimSim_low-res/tree/main/train\"\n",
    "\n",
    "    mode = 'train'\n",
    "    response = requests.get(data_base_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        folder_links = soup.find_all('a', class_=\"col-span-8 flex items-center hover:underline md:col-span-4 lg:col-span-3\")\n",
    "\n",
    "        for link in folder_links:\n",
    "            href = link.get('href')\n",
    "            if href[-7:] in validation_period:\n",
    "                mode = 'valid'\n",
    "            if href.startswith('/datasets/LEAP/ClimSim_low-res/tree/main/train/') and re.match(r'/datasets/LEAP/ClimSim_low-res/tree/main/train/\\d{4}-\\d{2}', href):\n",
    "                subfolder_url = urljoin(data_base_url, href)\n",
    "                if href[-7:] in training_period or href[-7:] in validation_period: \n",
    "                    response_sub = requests.get(subfolder_url)\n",
    "                    if response_sub.status_code == 200:\n",
    "                            soup_sub = BeautifulSoup(response_sub.text, 'html.parser')\n",
    "                            file_links = soup_sub.find_all('a', {'title' : 'Download file'})\n",
    "                            for file_link in file_links:\n",
    "                                href_sub = file_link.get('href')\n",
    "                                if re.match(r'/datasets/LEAP/ClimSim_low-res/resolve/main/train/(\\d{4}-\\d{2}/[^\\s]+)', href_sub):\n",
    "                                    subfile_url = urljoin(subfolder_url, href_sub)\n",
    "                                    download_data(subfile_url, mode)\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to fetch the page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression Output Function\n",
    "\n",
    "# Users input a start year-month and end year-month. The function then produces a list regular expressions\n",
    "# (in the format used in the preprocessing notebook) that can be used to extract files within a particular date range.\n",
    "\n",
    "def generate_file_regex(start_year_month, end_year_month):\n",
    "    # Split the start and end year-month strings into integers for processing.\n",
    "    start_year, start_month = map(int, start_year_month.split('-'))\n",
    "    end_year, end_month = map(int, end_year_month.split('-'))\n",
    "    \n",
    "    # Initialize an empty list to store the generated regular expressions.\n",
    "    regexps = []\n",
    "\n",
    "    # Iterate through the years from the start year to the end year (inclusive).\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Format the year as a 4-digit string, padding with zeros if necessary.\n",
    "        year_str = str(year).zfill(4)\n",
    "\n",
    "        # Determine the range of months to consider based on the current year.\n",
    "        if year == start_year and year == end_year:\n",
    "            month_range = range(start_month, end_month + 1)\n",
    "        elif year == start_year:\n",
    "            month_range = range(start_month, 13)\n",
    "        elif year == end_year:\n",
    "            month_range = range(1, end_month + 1)\n",
    "        else:\n",
    "            month_range = range(1, 13)\n",
    "\n",
    "        # Create a pattern for the months within the year, separated by the \"|\" symbol.\n",
    "        month_pattern = \"|\".join([str(month).zfill(2) for month in month_range])\n",
    "\n",
    "        # Construct the regular expression using the year and the month pattern.\n",
    "        regex = f'E3SM-MMF.mli.{year_str}-({month_pattern})-*-*.nc'\n",
    "\n",
    "        # Add the generated regular expression to the list.\n",
    "        regexps.append(regex)\n",
    "\n",
    "    # Return the list of generated regular expressions.\n",
    "    return regexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to allow user input of geographic and temporal data\n",
    "\n",
    "# Setting locations to \"all\" does not filter the data by location\n",
    "\n",
    "def climsim_geo_temporal_data_finder(locations, training_period, validation_period):\n",
    "    # Function to coerce location names into latitude and longitude\n",
    "    def coerce_to_lat_lon(location):\n",
    "        geolocator = Nominatim(user_agent=\"geo_locator\")\n",
    "        location_info = geolocator.geocode(location)\n",
    "        if location_info is not None:\n",
    "            return location_info.latitude, location_info.longitude\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Download the NetCDF file using Hugging Face's function\n",
    "    repo_id = \"LEAP/ClimSim_low-res\"  # Replace with the actual repository ID\n",
    "    filename = \"ClimSim_low-res_grid-info.nc\"  # Replace with the actual filename\n",
    "    local_filepath = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
    "\n",
    "    # Load the .nc file\n",
    "    nc_data = xr.open_dataset(local_filepath)\n",
    "\n",
    "    # Extract grid latitude and longitude values\n",
    "    latitude = nc_data[\"lat\"].values\n",
    "    longitude = nc_data[\"lon\"].values\n",
    "\n",
    "    # Define a function to find the nearest point\n",
    "    def find_nearest_lat_lon(user_lat, user_lon, latitude, longitude):\n",
    "        lat_diff = latitude - user_lat\n",
    "        lon_diff = longitude - user_lon\n",
    "        distance = np.sqrt(lat_diff ** 2 + lon_diff ** 2)\n",
    "        # Find the index of the minimum distance\n",
    "        idx = np.unravel_index(np.argmin(distance), distance.shape)\n",
    "        return idx\n",
    "\n",
    "    # Function to classify user locations\n",
    "    def classify_user_locations(user_locations, nc_data):\n",
    "        column_numbers = []\n",
    "        for user_location in user_locations:\n",
    "            if isinstance(user_location, str):\n",
    "                user_lat, user_lon = coerce_to_lat_lon(user_location)\n",
    "                if user_lat is None or user_lon is None:\n",
    "                    raise ValueError(f\"Invalid coordinates for location: {user_location}\")\n",
    "\n",
    "            elif isinstance(user_location, tuple) and len(user_location) == 2:\n",
    "                user_lat, user_lon = user_location\n",
    "            else:\n",
    "                raise ValueError(\"Invalid user location format\")\n",
    "\n",
    "            # Find the nearest latitude and longitude point\n",
    "            idx = find_nearest_lat_lon(user_lat, user_lon, latitude, longitude)\n",
    "\n",
    "            # Get the corresponding column number\n",
    "            column_number = nc_data[\"ncol\"][idx[0]].values\n",
    "            column_numbers.append(column_number)\n",
    "\n",
    "        return column_numbers\n",
    "\n",
    "    # Call the classification function with user input locations\n",
    "    if not locations or \"all\" in locations:\n",
    "        all_column_numbers = nc_data[\"ncol\"].values.tolist()\n",
    "        return all_column_numbers, [], []  # No regex patterns for all data\n",
    "    else:\n",
    "        latitude_longitude_list = []\n",
    "\n",
    "        for location in locations:\n",
    "            if isinstance(location, (str, tuple)):\n",
    "                latitude_longitude_list.append(location)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid user location format\")\n",
    "\n",
    "        column_numbers = classify_user_locations(latitude_longitude_list, nc_data)\n",
    "\n",
    "        unique_column_numbers = list(set(np.ravel(column_numbers)))\n",
    "\n",
    "        # Use the generate_file_regex function to get date range regexes\n",
    "        training_regexes = generate_file_regex(training_period[0], training_period[1])\n",
    "        validation_regexes = generate_file_regex(validation_period[0], validation_period[1])\n",
    "\n",
    "        return unique_column_numbers, training_regexes, validation_regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File already exists in ../data/e3sm_train/. Skipping download.\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-00000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-01200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-02400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-03600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-04800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-06000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-07200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-08400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-09600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-10800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-12000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-13200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-14400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-15600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-16800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-18000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-19200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-20400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-21600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-22800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-24000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-25200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-26400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-27600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-28800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-30000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-31200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-32400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-33600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-34800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-36000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-37200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-38400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-39600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-40800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-42000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-43200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-44400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-45600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-46800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-48000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-49200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-50400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-51600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-52800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-54000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-55200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-56400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-57600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-01-01-58800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-00000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-01200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-02400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-03600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-04800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-06000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-07200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-08400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-09600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-10800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-12000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-13200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-14400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-15600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-16800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-18000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-19200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-20400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-21600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-22800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-24000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-25200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-26400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-27600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-28800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-30000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-31200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-32400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-33600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-34800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-36000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-37200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-38400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-39600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-40800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-42000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-43200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-44400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-45600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-46800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-48000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-49200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-50400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-51600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-52800.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-54000.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-55200.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-56400.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-57600.nc\n",
      "File downloaded and saved to ../data/e3sm_valid/E3SM-MMF.mli.0005-02-01-58800.nc\n"
     ]
    }
   ],
   "source": [
    "training_period = (\"0001-06\", \"0004-06\")\n",
    "validation_period = (\"0005-01\", \"0005-02\")\n",
    "\n",
    "get_data(training_period, validation_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([26, 328, 178, 56, 58],\n",
       " ['E3SM-MMF.mli.0001-(06|07|08|09|10|11|12)-*-*.nc',\n",
       "  'E3SM-MMF.mli.0002-(01|02|03|04|05|06|07|08|09|10|11|12)-*-*.nc',\n",
       "  'E3SM-MMF.mli.0003-(01|02|03|04|05|06|07|08|09|10|11|12)-*-*.nc',\n",
       "  'E3SM-MMF.mli.0004-(01|02|03|04|05|06)-*-*.nc'],\n",
       " ['E3SM-MMF.mli.0008-(01|02|03|04|05|06|07|08|09|10|11|12)-*-*.nc',\n",
       "  'E3SM-MMF.mli.0009-(01|02|03|04|05|06)-*-*.nc'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Tester\n",
    "\n",
    "# Locations include place names, coordinates, duplicates, and closeby cities\n",
    "locations = [\"New York, USA\", \"Tokyo\", \"Detroit, MI\", \"Havana, Cuba\", (40.7128, -74.0060), (35.682839, 139.759455), (34.0522, -118.2437), (51.5074, -0.1278), \"Manaus, Brazil\"]\n",
    "\n",
    "training_period = (\"0001-06\", \"0004-06\")\n",
    "validation_period = (\"0008-01\", \"0009-06\")\n",
    "result = climsim_geo_temporal_data_finder(locations, training_period, validation_period)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
