{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T08:14:31.181236Z",
     "start_time": "2023-11-01T08:14:29.096492Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from huggingface_hub import hf_hub_download\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T08:14:31.211869Z",
     "start_time": "2023-11-01T08:14:31.187320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular Expression Output Function\n",
    "\n",
    "# Users input a start year-month and end year-month. The function then produces a list regular expressions\n",
    "# (in the format used in the preprocessing notebook) that can be used to extract files within a particular date range.\n",
    "\n",
    "def generate_file_regex(start_year_month, end_year_month):\n",
    "    # Split the start and end year-month strings into integers for processing.\n",
    "    start_year, start_month = map(int, start_year_month.split('-'))\n",
    "    end_year, end_month = map(int, end_year_month.split('-'))\n",
    "    \n",
    "    # Initialize an empty list to store the generated regular expressions.\n",
    "    regexps = []\n",
    "\n",
    "    # Iterate through the years from the start year to the end year (inclusive).\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Format the year as a 4-digit string, padding with zeros if necessary.\n",
    "        year_str = str(year).zfill(4)\n",
    "\n",
    "        # Determine the range of months to consider based on the current year.\n",
    "        if year == start_year and year == end_year:\n",
    "            month_range = range(start_month, end_month + 1)\n",
    "        elif year == start_year:\n",
    "            month_range = range(start_month, 13)\n",
    "        elif year == end_year:\n",
    "            month_range = range(1, end_month + 1)\n",
    "        else:\n",
    "            month_range = range(1, 13)\n",
    "\n",
    "        after_sep = []\n",
    "        before_sep = []\n",
    "        if len(month_range) >= 2:\n",
    "            for month in month_range:\n",
    "                if month > 9:\n",
    "                    after_sep.append(str(month)[1])\n",
    "                else:\n",
    "                    before_sep.append(str(month))\n",
    "            if before_sep != [] and after_sep != []:\n",
    "                before_sep_pattern = ''.join(before_sep)\n",
    "                before_sep = f'E3SM-MMF.mli.{year_str}-0[{before_sep_pattern}]-*-*.nc'\n",
    "                after_sep_pattern = ''.join(after_sep)\n",
    "                after_sep = f'E3SM-MMF.mli.{year_str}-1[{after_sep_pattern}]-*-*.nc'\n",
    "                regexps.append(before_sep)\n",
    "                regexps.append(after_sep)\n",
    "            elif before_sep != [] and after_sep == []:\n",
    "                before_sep_pattern = ''.join(before_sep)\n",
    "                before_sep = f'E3SM-MMF.mli.{year_str}-0[{before_sep_pattern}]-*-*.nc'\n",
    "                regexps.append(before_sep)\n",
    "            elif before_sep == [] and after_sep != []:\n",
    "                after_sep_pattern = ''.join(after_sep)\n",
    "                after_sep = f'E3SM-MMF.mli.{year_str}-1[{after_sep_pattern}]-*-*.nc'\n",
    "                regexps.append(after_sep)\n",
    "        else:\n",
    "            if list(month_range)[0] > 9:\n",
    "                month_pattern = str(list(month_range)[0])\n",
    "                regex = f'E3SM-MMF.mli.{year_str}-{month_pattern}-*-*.nc'\n",
    "                regexps.append(regex)\n",
    "            else:\n",
    "                month_pattern = str(list(month_range)[0]).zfill(2)\n",
    "                regex = f'E3SM-MMF.mli.{year_str}-{month_pattern}-*-*.nc'\n",
    "                regexps.append(regex)\n",
    "\n",
    "    # Return the list of generated regular expressions.\n",
    "    return regexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T08:14:34.515743Z",
     "start_time": "2023-11-01T08:14:34.491744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to allow user input of geographic and temporal data\n",
    "\n",
    "# Setting locations to \"all\" does not filter the data by location\n",
    "\n",
    "def climsim_geo_temporal_data_finder(locations, training_period, validation_period):\n",
    "    # Function to coerce location names into latitude and longitude\n",
    "    def coerce_to_lat_lon(location):\n",
    "        geolocator = Nominatim(user_agent=\"geo_locator\")\n",
    "        location_info = geolocator.geocode(location)\n",
    "        if location_info is not None:\n",
    "            return (location_info.latitude, location_info.longitude)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Download the NetCDF file using Hugging Face's function\n",
    "    repo_id = \"LEAP/ClimSim_low-res\"  # Replace with the actual repository ID\n",
    "    filename = \"ClimSim_low-res_grid-info.nc\"  # Replace with the actual filename\n",
    "    local_filepath = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
    "\n",
    "    # Load the .nc file\n",
    "    nc_data = xr.open_dataset(local_filepath)\n",
    "\n",
    "    # Extract grid latitude and longitude values\n",
    "    latitudes = nc_data[\"lat\"].values\n",
    "    longitudes = nc_data[\"lon\"].values\n",
    "    available_coordinates = list(zip(latitudes, longitudes))\n",
    "\n",
    "    # Define a function to find the nearest point\n",
    "    def find_nearest_lat_lon(user_coordinate):\n",
    "        distances = [geodesic(user_coordinate, coordinate).kilometers for coordinate in available_coordinates]\n",
    "        # Find the index of the minimum distance\n",
    "        idx = distances.index(min(distances))\n",
    "        return idx\n",
    "\n",
    "    # Function to classify user locations\n",
    "    def classify_user_locations(user_locations, nc_data):\n",
    "        column_numbers = []\n",
    "        for user_location in user_locations:\n",
    "            if isinstance(user_location, str):\n",
    "                user_coordinate = coerce_to_lat_lon(user_location)\n",
    "                if user_coordinate[0] is None or user_coordinate[1] is None:\n",
    "                    raise ValueError(f\"Invalid coordinates for location: {user_location}\")\n",
    "\n",
    "            elif isinstance(user_location, tuple) and len(user_location) == 2:\n",
    "                user_coordinate = user_location\n",
    "            else:\n",
    "                raise ValueError(\"Invalid user location format\")\n",
    "\n",
    "            # Find column index of the nearest latitude and longitude point\n",
    "            idx = find_nearest_lat_lon(user_coordinate)\n",
    "            column_numbers.append(idx)\n",
    "\n",
    "        return column_numbers\n",
    "\n",
    "    # Call the classification function with user input locations\n",
    "    if not locations or \"all\" in locations:\n",
    "        all_column_numbers = nc_data[\"ncol\"].values.tolist()\n",
    "        training_regexes = generate_file_regex(training_period[0], training_period[1])\n",
    "        validation_regexes = generate_file_regex(validation_period[0], validation_period[1])\n",
    "        return all_column_numbers, training_regexes, validation_regexes\n",
    "    else:\n",
    "        latitude_longitude_list = []\n",
    "        for location in locations:\n",
    "            if isinstance(location, (str, tuple)):\n",
    "                latitude_longitude_list.append(location)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid user location format\")\n",
    "\n",
    "        column_numbers = classify_user_locations(latitude_longitude_list, nc_data)\n",
    "\n",
    "        unique_column_numbers = list(set(column_numbers))\n",
    "\n",
    "        # Use the generate_file_regex function to get date range regexes\n",
    "        training_regexes = generate_file_regex(training_period[0], training_period[1])\n",
    "        validation_regexes = generate_file_regex(validation_period[0], validation_period[1])\n",
    "\n",
    "        return unique_column_numbers, training_regexes, validation_regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T08:14:45.387913Z",
     "start_time": "2023-11-01T08:14:36.571503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([325, 178, 243, 248, 250, 251, 222],\n",
       " ['E3SM-MMF.mli.0001-0[6789]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0001-1[012]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0002-0[123456789]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0002-1[012]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0003-0[123456789]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0003-1[012]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0004-0[123456]-*-*.nc'],\n",
       " ['E3SM-MMF.mli.0008-0[123456789]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0008-1[012]-*-*.nc',\n",
       "  'E3SM-MMF.mli.0009-0[123456]-*-*.nc'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Tester\n",
    "\n",
    "# Locations include place names, coordinates, duplicates, and closeby cities\n",
    "locations = [\"New York, USA\", \"Tokyo\", \"Detroit, MI\", \"Havana, Cuba\", (40.7128, -74.0060), (35.682839, 139.759455), (34.0522, -118.2437), (51.5074, -0.1278), \"Manaus, Brazil\"]\n",
    "\n",
    "training_period =  [\"0001-06\", \"0004-06\"]\n",
    "validation_period = [\"0008-01\", \"0009-06\"]\n",
    "result = climsim_geo_temporal_data_finder(locations, training_period, validation_period)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
